{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "\n",
    "This week covers part of speech tagging in more detail.\n",
    "\n",
    "Overview\n",
    "\n",
    "* [**Tagging and Tagsets**](#Tagging-and-Tagsets)\n",
    "* [**Heuristic-based Tagging**](#Heuristic-based-Tagging)\n",
    "* [**N-Gram Tagging**](#N-Gram-Tagging)\n",
    "* [**Visualizing Errors**](#Visualizing-Errors)\n",
    "* [**State-of-the-art Taggers**](#State-of-the-art-Taggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import some things to work with\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_news = brown.tagged_sents(categories='news')\n",
    "brown_news = brown.sents(categories='news')\n",
    "brown_tagged_scifi = brown.tagged_sents(categories='science_fiction')\n",
    "brown_scifi = brown.sents(categories='science_fiction')\n",
    "\n",
    "sent = nltk.word_tokenize('From each according to their ability, to each according to their need.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging and Tagsets\n",
    "\n",
    "Recall that part-of-speech tagging assigns a word category to each token in a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories are defined by **tagsets**. The example above uses the English Penn Treebank tagset, but others are available, even cross-lingual sets. Part-of-speech tagging isn't just for words, but also punctuation and sometimes parts of words. For example, the [Mecab](https://taku910.github.io/mecab/) morphological analyzer for Japanese does both word segmentation and tagging, and morphological segments get their own tag (note: this is shown executed in a terminal, not Python):\n",
    "\n",
    "```bash\n",
    "$ mecab -Osimple <<< \"能力に応じて働き、必要に応じて受け取る。\"\n",
    "能力\t名詞-一般\n",
    "に\t助詞-格助詞-一般\n",
    "応じ\t動詞-自立\n",
    "て\t助詞-接続助詞\n",
    "働き\t動詞-自立\n",
    "、\t記号-読点\n",
    "必要\t名詞-形容動詞語幹\n",
    "に\t助詞-副詞化\n",
    "応じ\t動詞-自立\n",
    "て\t助詞-接続助詞\n",
    "受け取る\t動詞-自立\n",
    "。\t記号-句点\n",
    "EOS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic-based Tagging\n",
    "\n",
    "A simple way to tag is to use basic statistics or language knowledge to create a tagger with hand-built rules.\n",
    "\n",
    "\n",
    "### Default Tagger\n",
    "\n",
    "The default tagger assigns the same tag to all tokens. This is useless for general purpose uses, but it is useful for establishing baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tagger = nltk.DefaultTagger('NN')\n",
    "nn_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tagger.evaluate(brown_tagged_scifi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why choose `NN`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(tag for sent in brown_tagged_news for _, tag in sent)\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: try using a different default tag and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern-based Tagging\n",
    "\n",
    "With a bit more information about the forms of the words, the tagger can do better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(\n",
    "    [(r'.*ing$', 'VBG'),                # gerunds\n",
    "     (r'.*ed$', 'VBD'),                 # simple past\n",
    "     (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "     (r'.*ould$', 'MD'),                # modals\n",
    "     (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "     (r'.*s$', 'NNS'),                  # plural nouns\n",
    "     (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "     (r'.*', 'NN')                      # nouns (default)\n",
    "    ])\n",
    "regexp_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_scifi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: try adding some more rules, or rearranging them, to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger2 = nltk.RegexpTagger(\n",
    "    [(r'.*ing$', 'VBG'),                # gerunds\n",
    "     (r'.*ed$', 'VBD'),                 # simple past\n",
    "     (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "     (r'.*ould$', 'MD'),                # modals\n",
    "     (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "     (r'.*s$', 'NNS'),                  # plural nouns\n",
    "     (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "     (r'.*', 'NN')                      # nouns (default)\n",
    "    ])\n",
    "regexp_tagger2.tag(sent)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger2.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger2.evaluate(brown_tagged_scifi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Tagging\n",
    "\n",
    "Rather than trying to hand-build many rules to cover all of a language, we can **train** a tagger to **learn** the best tags for each word. This uses statistical inference based on hand-tagged (gold) data, which we assume is correct.\n",
    "\n",
    "### Unigram Tagging\n",
    "\n",
    "First we will start by assigning the tag most frequently associated with a particular word form for the 100 most frequent words (all other words get a tag of `None`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the N most frequent words in the Brown corpus's \"news\" category \n",
    "N = 100\n",
    "\n",
    "# TODO: find the most likely tags for those words (create a dict mapping {word: tag})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build a UnigramTagger using the most likely tags as a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: evaluate this tagger on the news and scifi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: increase `N`, then retrain, then re-evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(brown_tagged_news)\n",
    "baseline_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram and Trigram Tagging\n",
    "\n",
    "Now let's give the model a bit of context by using bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_news)\n",
    "bigram_tagger.tag(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger.evaluate(brown_tagged_scifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(brown_tagged_news)\n",
    "trigram_tagger.evaluate(brown_tagged_news)"
   ]
  },
  {
   "source": [
    "Did the accuracy go up with more n-grams? Try using a backoff and try again:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger = ...\n",
    "trigram_tagger = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross-validation\n",
    "\n",
    "Split the training data (`brown_tagged_news` or `brown_tagged_scifi`) for k-fold cross validation. For some value `k` (say, 5), set aside `1/k` for test data and the remainder for training data. Train a bigram tagger with backoff on the training data, then evaluate on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = brown_tagged_news\n",
    "\n",
    "k = 5\n",
    "index = int( (1/k) * len(brown_tagged_news) )\n",
    "accs = []\n",
    "\n",
    "for i in range(k):\n",
    "    # TODO: extract 1/k of the data for testing\n",
    "    # TODO: extract (k-1)/k of the data for training\n",
    "    # (hint, use 'index' and 'i' to find where to split)\n",
    "    test_data = news[]\n",
    "    train_data = news[] + news[]\n",
    "\n",
    "    # TODO: create a bigram tagger that backs off to a unigram tagger\n",
    "    # trained using the extracted training data\n",
    "    unigram_tagger = ...\n",
    "    bigram_tagger = ...\n",
    "    # TODO: now evaluate on the test data\n",
    "    acc = ...\n",
    "    print(i, acc)\n",
    "    accs.append(acc)\n",
    "print(sum(accs)/k)  # print the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_tagged = bigram_tagger.tag(brown.words(categories='news'))\n",
    "hand_tagged = brown.tagged_words(categories='news')\n",
    "assert len(auto_tagged) == len(hand_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "t2t_cfd = nltk.ConditionalFreqDist(\n",
    "    (t1[1], t2[1])\n",
    "    for t1, t2 in zip(auto_tagged, hand_tagged)\n",
    "    if t1[1] != t2[1])\n",
    "t2t_cfd['NN'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art Taggers\n",
    "\n",
    "The http://nlpprogress.com/ website tracks the start-of-the-art (SOTA) performance of many different NLP tasks. For part of speech tagging (http://nlpprogress.com/english/part-of-speech_tagging.html), the top systems get over 97% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "84708403546ecd1e3944b1508f8d5c894da9f0666a04f38efb485e053f6828a8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}