{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('env')",
   "display_name": "Python 3.8.2 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "84708403546ecd1e3944b1508f8d5c894da9f0666a04f38efb485e053f6828a8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Week 8\n",
    "\n",
    "Regular expressions, stemming, lemmatization, and segmentation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Regex Basics\n",
    "\n",
    "First import the `re` library:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "source": [
    "Then use `re.match()` to match the following strings:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 1), match=&#39;a&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "re.match(r'a', 'a') # a single 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 8), match=&#39;aaaaaaaa&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "re.match(r'a+', 'aaaaaaaa')  # multiple 'a's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 26), match=&#39;abcdefghijklmnopqrstuvwxyz&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "re.match(r'[a-z]*', 'abcdefghijklmnopqrstuvwxyz')  # any letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 26), match=&#39;abcdefghijklmnopqrstuvwxyz&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "re.match(r'\\w*', 'abcdefghijklmnopqrstuvwxyz')  # any letter (alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 6), match=&#39;AaBbCc&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "re.match(r'[A-Ca-c]*', 'AaBbCc')  # upper and lower-case letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;re.Match object; span=(0, 3), match=&#39;Aあ啊&#39;&gt;"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "re.match(r'\\w+', 'Aあ啊')  # all word characters (hint, use a character class)"
   ]
  },
  {
   "source": [
    "## Searching\n",
    "\n",
    "Now use `re.search()` to find a match while ignoring false matches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&lt;re.Match object; span=(11, 12), match=&#39;a&#39;&gt;]\n[&lt;re.Match object; span=(0, 2), match=&#39;An&#39;&gt;]\n[&lt;re.Match object; span=(0, 1), match=&#39;A&#39;&gt;, &lt;re.Match object; span=(14, 16), match=&#39;an&#39;&gt;]\n"
    }
   ],
   "source": [
    "# match the article 'a' but not other 'a's\n",
    "for s in ('Apples are a fruit', 'An apple each day', 'A pear is not an apple'):\n",
    "    print(list(re.finditer(r'\\b([Aa]n?|[Tt]he)\\b', s)))"
   ]
  },
  {
   "source": [
    "Use `re.findall()` over the text of Jane Austen's *Sense and Sensibility* to find hyphenated words:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sense = nltk.corpus.gutenberg.raw('austen-sense.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{&#39;Bond-street&#39;,\n &#39;Cold-hearted&#39;,\n &#39;Good-by&#39;,\n &#39;Hanover-square&#39;,\n &#39;High-church&#39;,\n &#39;Mansion-house&#39;,\n &#39;Mid-summer&#39;,\n &#39;To-morrow&#39;,\n &#39;a-day&#39;,\n &#39;a-piece&#39;,\n &#39;a-year&#39;,\n &#39;after-days&#39;,\n &#39;bank-notes&#39;,\n &#39;bed-chamber&#39;,\n &#39;bed-rooms&#39;,\n &#39;before-hand&#39;,\n &#39;bowling-green&#39;,\n &#39;breakfast-room&#39;,\n &#39;broken-hearted&#39;,\n &#39;brother-in-law&#39;,\n &#39;by-and-by&#39;,\n &#39;card-table&#39;,\n &#39;card-tables&#39;,\n &#39;carpet-work&#39;,\n &#39;chimney-board&#39;,\n &#39;cold-hearted&#39;,\n &#39;common-place&#39;,\n &#39;dairy-maid&#39;,\n &#39;daughter-in-law&#39;,\n &#39;death-like&#39;,\n &#39;dining-room&#39;,\n &#39;dove-cote&#39;,\n &#39;drawing-room&#39;,\n &#39;drawing-table&#39;,\n &#39;dressing-closet&#39;,\n &#39;dressing-room&#39;,\n &#39;ear-rings&#39;,\n &#39;farm-house&#39;,\n &#39;flower-garden&#39;,\n &#39;free-spoken&#39;,\n &#39;fruit-trees&#39;,\n &#39;gentleman-like&#39;,\n &#39;good-breeding&#39;,\n &#39;good-for-nothing&#39;,\n &#39;good-hearted&#39;,\n &#39;good-humored&#39;,\n &#39;good-humoured&#39;,\n &#39;good-nature&#39;,\n &#39;good-natured&#39;,\n &#39;good-will&#39;,\n &#39;green-house&#39;,\n &#39;ground-floor&#39;,\n &#39;hand-writing&#39;,\n &#39;hard-hearted&#39;,\n &#39;head-aches&#39;,\n &#39;high-minded&#39;,\n &#39;house-maid&#39;,\n &#39;ill-bred&#39;,\n &#39;ill-breeding&#39;,\n &#39;ill-disposed&#39;,\n &#39;ill-humour&#39;,\n &#39;ill-judged&#39;,\n &#39;ill-nature&#39;,\n &#39;ill-natured&#39;,\n &#39;ill-suited&#39;,\n &#39;ill-timed&#39;,\n &#39;ill-treatment&#39;,\n &#39;ill-will&#39;,\n &#39;ill-wind&#39;,\n &#39;land-tax&#39;,\n &#39;landing-place&#39;,\n &#39;last-arrived&#39;,\n &#39;lavender-water&#39;,\n &#39;letter-writing&#39;,\n &#39;life-interest&#39;,\n &#39;light-headed&#39;,\n &#39;long-established&#39;,\n &#39;long-expected&#39;,\n &#39;love-child&#39;,\n &#39;low-spirited&#39;,\n &#39;lying-in&#39;,\n &#39;make-believe&#39;,\n &#39;man-servant&#39;,\n &#39;mansion-house&#39;,\n &#39;mantel-piece&#39;,\n &#39;mean-spirited&#39;,\n &#39;modern-built&#39;,\n &#39;mother-in-law&#39;,\n &#39;mountain-ash&#39;,\n &#39;mulberry-tree&#39;,\n &#39;music-sellers&#39;,\n &#39;narrow-minded&#39;,\n &#39;new-furnished&#39;,\n &#39;now-a-days&#39;,\n &#39;old-fashioned&#39;,\n &#39;over-powered&#39;,\n &#39;over-set&#39;,\n &#39;parsonage-house&#39;,\n &#39;piano-forte&#39;,\n &#39;pleasure-grounds&#39;,\n &#39;pocket-book&#39;,\n &#39;post-boys&#39;,\n &#39;post-chaise&#39;,\n &#39;post-horses&#39;,\n &#39;poultry-yard&#39;,\n &#39;pre-arranged&#39;,\n &#39;pre-arranging&#39;,\n &#39;pre-determined&#39;,\n &#39;print-shops&#39;,\n &#39;proud-looking&#39;,\n &#39;purchase-money&#39;,\n &#39;quick-sighted&#39;,\n &#39;re-assurance&#39;,\n &#39;re-establish&#39;,\n &#39;re-established&#39;,\n &#39;sang-froid&#39;,\n &#39;self-command&#39;,\n &#39;self-complacency&#39;,\n &#39;self-condemnation&#39;,\n &#39;self-consequence&#39;,\n &#39;self-control&#39;,\n &#39;self-denial&#39;,\n &#39;self-destruction&#39;,\n &#39;self-evident&#39;,\n &#39;self-importance&#39;,\n &#39;self-interest&#39;,\n &#39;self-mortification&#39;,\n &#39;self-provident&#39;,\n &#39;self-provocation&#39;,\n &#39;self-reproach&#39;,\n &#39;self-reproving&#39;,\n &#39;shooting-jacket&#39;,\n &#39;side-board&#39;,\n &#39;sister-in-law&#39;,\n &#39;sisters-in-law&#39;,\n &#39;sitting-room&#39;,\n &#39;son-in-law&#39;,\n &#39;sons-in-law&#39;,\n &#39;south-east&#39;,\n &#39;south-westerly&#39;,\n &#39;spunging-house&#39;,\n &#39;stew-ponds&#39;,\n &#39;summer-rooms&#39;,\n &#39;tea-table&#39;,\n &#39;tea-things&#39;,\n &#39;tete-a-tete&#39;,\n &#39;thirty-five&#39;,\n &#39;thirty-six&#39;,\n &#39;to-day&#39;,\n &#39;to-do&#39;,\n &#39;to-morrow&#39;,\n &#39;to-night&#39;,\n &#39;toothpick-case&#39;,\n &#39;toothpick-cases&#39;,\n &#39;turnpike-road&#39;,\n &#39;twelve-month&#39;,\n &#39;twenty-four&#39;,\n &#39;two-penny&#39;,\n &#39;unlover-like&#39;,\n &#39;unthought-of&#39;,\n &#39;watch-tower&#39;,\n &#39;well-behaved&#39;,\n &#39;well-bred&#39;,\n &#39;well-disposed&#39;,\n &#39;well-established&#39;,\n &#39;well-informed&#39;,\n &#39;well-judging&#39;,\n &#39;well-known&#39;,\n &#39;well-meaning&#39;,\n &#39;well-meant&#39;,\n &#39;well-wisher&#39;,\n &#39;window-seats&#39;,\n &#39;wine-glass&#39;,\n &#39;work-bags&#39;}"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "set(re.findall(r'\\w+(?:-\\w+)+', sense))"
   ]
  },
  {
   "source": [
    "## Substitution\n",
    "\n",
    "Now detect -y words inflected as -ies (e.g., *fly* -> *flies*). Save them to a set called `ies`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{&#39;Davies&#39;,\n &#39;Indies&#39;,\n &#39;abilities&#39;,\n &#39;agonies&#39;,\n &#39;annuities&#39;,\n &#39;apologies&#39;,\n &#39;assemblies&#39;,\n &#39;assiduities&#39;,\n &#39;beauties&#39;,\n &#39;carries&#39;,\n &#39;certainties&#39;,\n &#39;cherries&#39;,\n &#39;civilities&#39;,\n &#39;cries&#39;,\n &#39;deficiencies&#39;,\n &#39;delicacies&#39;,\n &#39;dies&#39;,\n &#39;difficulties&#39;,\n &#39;duties&#39;,\n &#39;enquiries&#39;,\n &#39;entreaties&#39;,\n &#39;excellencies&#39;,\n &#39;families&#39;,\n &#39;flatteries&#39;,\n &#39;implies&#39;,\n &#39;injuries&#39;,\n &#39;inquiries&#39;,\n &#39;jealousies&#39;,\n &#39;ladies&#39;,\n &#39;legacies&#39;,\n &#39;lies&#39;,\n &#39;marries&#39;,\n &#39;opportunities&#39;,\n &#39;parties&#39;,\n &#39;probabilities&#39;,\n &#39;promontories&#39;,\n &#39;propensities&#39;,\n &#39;prophecies&#39;,\n &#39;puppies&#39;,\n &#39;remedies&#39;,\n &#39;scrutinies&#39;,\n &#39;series&#39;,\n &#39;shrubberies&#39;,\n &#39;species&#39;,\n &#39;studies&#39;,\n &#39;tries&#39;}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ies = set(re.findall(r'(?:\\w+-)*\\w+ies\\b', sense))\n",
    "ies"
   ]
  },
  {
   "source": [
    "Use `re.sub()` to try and deinflect them to their dictionary form, and check if they are in the dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "YES parties\nYES apologies\nYES flatteries\nYES families\nYES difficulties\nYES ladies\nYES civilities\nYES prophecies\nYES lies\nYES assiduities\nYES delicacies\nYES Davies\nYES enquiries\nYES excellencies\nYES propensities\nYES shrubberies\nNO  dies\nYES inquiries\nYES beauties\nYES studies\nYES puppies\nYES Indies\nNO  species\nYES injuries\nYES jealousies\nYES deficiencies\nYES certainties\nYES tries\nYES scrutinies\nYES assemblies\nYES agonies\nYES opportunities\nYES annuities\nYES marries\nYES remedies\nYES implies\nYES cherries\nYES probabilities\nYES cries\nYES entreaties\nYES duties\nYES legacies\nNO  series\nYES abilities\nYES promontories\nYES carries\n"
    }
   ],
   "source": [
    "for word in ies:\n",
    "    y = re.sub(r'ies$', r'y', word)\n",
    "    if y.lower() in WORDS:\n",
    "        print('YES', word)\n",
    "    else:\n",
    "        print('NO ', word)"
   ]
  },
  {
   "source": [
    "# Stemming and Lemmatization\n",
    "\n",
    "Above the `re.sub()` call replaced `ies` with `y`, and this is a crude form of lemmatization. Stemming is if we removed the `ies` but did not insert anything. Stemming is more robust to novel or mispelled words, but lemmatization gives cleaner results (when it works). In the NLTK, you may notice that the WordNet module can do some lemmatization. For instance, it can find synsets for *catch* when queried with *caught*:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Synset(&#39;catch.v.01&#39;),\n Synset(&#39;catch.v.02&#39;),\n Synset(&#39;get.v.19&#39;),\n Synset(&#39;catch.v.04&#39;),\n Synset(&#39;get.v.11&#39;),\n Synset(&#39;hitch.v.01&#39;),\n Synset(&#39;catch.v.07&#39;),\n Synset(&#39;capture.v.06&#39;),\n Synset(&#39;catch.v.09&#39;),\n Synset(&#39;catch.v.10&#39;),\n Synset(&#39;overtake.v.01&#39;),\n Synset(&#39;catch.v.12&#39;),\n Synset(&#39;catch.v.13&#39;),\n Synset(&#39;catch.v.14&#39;),\n Synset(&#39;watch.v.03&#39;),\n Synset(&#39;catch.v.16&#39;),\n Synset(&#39;trip_up.v.01&#39;),\n Synset(&#39;catch.v.18&#39;),\n Synset(&#39;catch.v.19&#39;),\n Synset(&#39;catch.v.20&#39;),\n Synset(&#39;catch.v.21&#39;),\n Synset(&#39;catch.v.22&#39;),\n Synset(&#39;capture.v.02&#39;),\n Synset(&#39;catch.v.24&#39;),\n Synset(&#39;catch.v.25&#39;),\n Synset(&#39;catch.v.26&#39;),\n Synset(&#39;catch.v.27&#39;),\n Synset(&#39;catch.v.28&#39;),\n Synset(&#39;catch.v.29&#39;)]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('caught')"
   ]
  },
  {
   "source": [
    "This works by applying some basic morphological processing (like our 'ies' -> 'y' substitution) and looking if the result exists in WordNet. WordNet also contains some irregular forms, which is how it finds 'catch' for 'caught'. You can make use of WordNet's lemmatizer without using WordNet itself (but note it only works for English):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;catch&#39;"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "wnl.lemmatize('caught', pos='v')"
   ]
  },
  {
   "source": [
    "But note that the default part-of-speech is 'n' (noun):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on method lemmatize in module nltk.stem.wordnet:\n\nlemmatize(word, pos=&#39;n&#39;) method of nltk.stem.wordnet.WordNetLemmatizer instance\n\n"
    }
   ],
   "source": [
    "help(wnl.lemmatize)"
   ]
  },
  {
   "source": [
    "So it won't work well on verbs if the part-of-speech is not specified, or in geneneral when the part-of-speech is incorrect:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;caught&#39;"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "wnl.lemmatize('caught')  # pos='n' is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;ox&#39;"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "wnl.lemmatize('oxen')  # default works well for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;oxen&#39;"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "wnl.lemmatize('oxen', pos='v')  # specifying the wrong pos is also bad"
   ]
  }
 ]
}